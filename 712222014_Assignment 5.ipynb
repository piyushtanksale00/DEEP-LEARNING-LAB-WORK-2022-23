{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUSHIKESH SANJIV TANKSALE.\n",
    "712222014 Deep Learning 2022-23 SEM II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voORwW-1CDb-",
    "outputId": "0732ce00-1487-43dc-9abd-f791689be9b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with initialization: zeros, activation: sigmoid\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3025 - accuracy: 0.1095 - val_loss: 2.3021 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3024 - accuracy: 0.1097 - val_loss: 2.3033 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3024 - accuracy: 0.1114 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3025 - accuracy: 0.1098 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3025 - accuracy: 0.1107 - val_loss: 2.3027 - val_accuracy: 0.1028\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3025 - accuracy: 0.1096 - val_loss: 2.3020 - val_accuracy: 0.1028\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3025 - accuracy: 0.1093 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3024 - accuracy: 0.1099 - val_loss: 2.3021 - val_accuracy: 0.1028\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3024 - accuracy: 0.1101 - val_loss: 2.3020 - val_accuracy: 0.1028\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3022 - accuracy: 0.1094 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Running experiment with initialization: zeros, activation: tanh\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3017 - accuracy: 0.1121 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3012 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Running experiment with initialization: zeros, activation: relu\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3016 - accuracy: 0.1113 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Running experiment with initialization: zeros, activation: leaky_relu\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3016 - accuracy: 0.1117 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Running experiment with initialization: random_normal, activation: sigmoid\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.3007 - accuracy: 0.1128 - val_loss: 2.2958 - val_accuracy: 0.1135\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2921 - accuracy: 0.1339 - val_loss: 2.2861 - val_accuracy: 0.1925\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2731 - accuracy: 0.1872 - val_loss: 2.2526 - val_accuracy: 0.2536\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.1957 - accuracy: 0.3168 - val_loss: 2.0917 - val_accuracy: 0.3803\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8874 - accuracy: 0.4337 - val_loss: 1.6376 - val_accuracy: 0.4966\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.4637 - accuracy: 0.5297 - val_loss: 1.2971 - val_accuracy: 0.5693\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1994 - accuracy: 0.6058 - val_loss: 1.0839 - val_accuracy: 0.6538\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.0085 - accuracy: 0.6849 - val_loss: 0.9155 - val_accuracy: 0.7137\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8662 - accuracy: 0.7377 - val_loss: 0.8000 - val_accuracy: 0.7639\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7675 - accuracy: 0.7731 - val_loss: 0.7147 - val_accuracy: 0.7963\n",
      "Running experiment with initialization: random_normal, activation: tanh\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.2213 - accuracy: 0.7132 - val_loss: 0.5260 - val_accuracy: 0.8655\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4279 - accuracy: 0.8845 - val_loss: 0.3485 - val_accuracy: 0.9019\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3292 - accuracy: 0.9074 - val_loss: 0.2940 - val_accuracy: 0.9154\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2861 - accuracy: 0.9183 - val_loss: 0.2602 - val_accuracy: 0.9262\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2572 - accuracy: 0.9265 - val_loss: 0.2352 - val_accuracy: 0.9302\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2335 - accuracy: 0.9327 - val_loss: 0.2177 - val_accuracy: 0.9346\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2139 - accuracy: 0.9386 - val_loss: 0.1990 - val_accuracy: 0.9422\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1968 - accuracy: 0.9430 - val_loss: 0.1863 - val_accuracy: 0.9459\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1823 - accuracy: 0.9481 - val_loss: 0.1724 - val_accuracy: 0.9492\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1693 - accuracy: 0.9514 - val_loss: 0.1625 - val_accuracy: 0.9521\n",
      "Running experiment with initialization: random_normal, activation: relu\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3985 - accuracy: 0.5954 - val_loss: 0.5585 - val_accuracy: 0.8407\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4444 - accuracy: 0.8725 - val_loss: 0.3541 - val_accuracy: 0.8997\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3437 - accuracy: 0.9011 - val_loss: 0.3040 - val_accuracy: 0.9134\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3017 - accuracy: 0.9131 - val_loss: 0.2733 - val_accuracy: 0.9231\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2722 - accuracy: 0.9216 - val_loss: 0.2519 - val_accuracy: 0.9281\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2466 - accuracy: 0.9287 - val_loss: 0.2324 - val_accuracy: 0.9309\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2246 - accuracy: 0.9359 - val_loss: 0.2180 - val_accuracy: 0.9355\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2062 - accuracy: 0.9407 - val_loss: 0.1978 - val_accuracy: 0.9438\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1902 - accuracy: 0.9449 - val_loss: 0.1802 - val_accuracy: 0.9474\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1760 - accuracy: 0.9488 - val_loss: 0.1767 - val_accuracy: 0.9500\n",
      "Running experiment with initialization: random_normal, activation: leaky_relu\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 1.3675 - accuracy: 0.6152 - val_loss: 0.5204 - val_accuracy: 0.8504\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4298 - accuracy: 0.8767 - val_loss: 0.3563 - val_accuracy: 0.8945\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3408 - accuracy: 0.9024 - val_loss: 0.3060 - val_accuracy: 0.9126\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3032 - accuracy: 0.9126 - val_loss: 0.2810 - val_accuracy: 0.9190\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2773 - accuracy: 0.9200 - val_loss: 0.2573 - val_accuracy: 0.9270\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2555 - accuracy: 0.9269 - val_loss: 0.2373 - val_accuracy: 0.9301\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2365 - accuracy: 0.9316 - val_loss: 0.2211 - val_accuracy: 0.9363\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2192 - accuracy: 0.9370 - val_loss: 0.2088 - val_accuracy: 0.9389\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2035 - accuracy: 0.9414 - val_loss: 0.1948 - val_accuracy: 0.9423\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1890 - accuracy: 0.9450 - val_loss: 0.1826 - val_accuracy: 0.9455\n",
      "Running experiment with initialization: glorot_uniform, activation: sigmoid\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2219 - accuracy: 0.3273 - val_loss: 2.0939 - val_accuracy: 0.4870\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8389 - accuracy: 0.5918 - val_loss: 1.5098 - val_accuracy: 0.6553\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.2587 - accuracy: 0.7009 - val_loss: 1.0246 - val_accuracy: 0.7547\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8970 - accuracy: 0.7770 - val_loss: 0.7678 - val_accuracy: 0.8132\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7059 - accuracy: 0.8194 - val_loss: 0.6273 - val_accuracy: 0.8394\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5946 - accuracy: 0.8461 - val_loss: 0.5374 - val_accuracy: 0.8588\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5211 - accuracy: 0.8634 - val_loss: 0.4761 - val_accuracy: 0.8743\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4689 - accuracy: 0.8759 - val_loss: 0.4323 - val_accuracy: 0.8844\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4308 - accuracy: 0.8848 - val_loss: 0.4007 - val_accuracy: 0.8909\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4022 - accuracy: 0.8911 - val_loss: 0.3771 - val_accuracy: 0.8976\n",
      "Running experiment with initialization: glorot_uniform, activation: tanh\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6324 - accuracy: 0.8400 - val_loss: 0.3488 - val_accuracy: 0.9051\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3249 - accuracy: 0.9093 - val_loss: 0.2827 - val_accuracy: 0.9210\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2757 - accuracy: 0.9215 - val_loss: 0.2485 - val_accuracy: 0.9297\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2448 - accuracy: 0.9293 - val_loss: 0.2281 - val_accuracy: 0.9353\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2213 - accuracy: 0.9359 - val_loss: 0.2079 - val_accuracy: 0.9422\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2018 - accuracy: 0.9417 - val_loss: 0.1914 - val_accuracy: 0.9459\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1856 - accuracy: 0.9470 - val_loss: 0.1795 - val_accuracy: 0.9487\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1721 - accuracy: 0.9508 - val_loss: 0.1666 - val_accuracy: 0.9506\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1603 - accuracy: 0.9538 - val_loss: 0.1567 - val_accuracy: 0.9546\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1500 - accuracy: 0.9571 - val_loss: 0.1493 - val_accuracy: 0.9568\n",
      "Running experiment with initialization: glorot_uniform, activation: relu\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 3ms/step - loss: 0.6734 - accuracy: 0.8229 - val_loss: 0.3284 - val_accuracy: 0.9051\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3085 - accuracy: 0.9114 - val_loss: 0.2682 - val_accuracy: 0.9224\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2572 - accuracy: 0.9249 - val_loss: 0.2284 - val_accuracy: 0.9341\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2239 - accuracy: 0.9356 - val_loss: 0.2118 - val_accuracy: 0.9385\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1986 - accuracy: 0.9422 - val_loss: 0.1878 - val_accuracy: 0.9439\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1784 - accuracy: 0.9481 - val_loss: 0.1755 - val_accuracy: 0.9474\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1620 - accuracy: 0.9526 - val_loss: 0.1657 - val_accuracy: 0.9495\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1490 - accuracy: 0.9568 - val_loss: 0.1461 - val_accuracy: 0.9572\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1373 - accuracy: 0.9606 - val_loss: 0.1418 - val_accuracy: 0.9575\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1275 - accuracy: 0.9630 - val_loss: 0.1328 - val_accuracy: 0.9602\n",
      "Running experiment with initialization: glorot_uniform, activation: leaky_relu\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6712 - accuracy: 0.8168 - val_loss: 0.3288 - val_accuracy: 0.9071\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3104 - accuracy: 0.9109 - val_loss: 0.2722 - val_accuracy: 0.9222\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2646 - accuracy: 0.9246 - val_loss: 0.2429 - val_accuracy: 0.9306\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2352 - accuracy: 0.9324 - val_loss: 0.2159 - val_accuracy: 0.9388\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2121 - accuracy: 0.9392 - val_loss: 0.2010 - val_accuracy: 0.9428\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1938 - accuracy: 0.9447 - val_loss: 0.1839 - val_accuracy: 0.9464\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1785 - accuracy: 0.9488 - val_loss: 0.1718 - val_accuracy: 0.9495\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1658 - accuracy: 0.9522 - val_loss: 0.1664 - val_accuracy: 0.9516\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1552 - accuracy: 0.9559 - val_loss: 0.1536 - val_accuracy: 0.9548\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1454 - accuracy: 0.9584 - val_loss: 0.1447 - val_accuracy: 0.9579\n",
      "Running experiment with initialization: he_normal, activation: sigmoid\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1380 - accuracy: 0.4096 - val_loss: 1.8764 - val_accuracy: 0.6187\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.5284 - accuracy: 0.6824 - val_loss: 1.1798 - val_accuracy: 0.7639\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9932 - accuracy: 0.7715 - val_loss: 0.8207 - val_accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7431 - accuracy: 0.8173 - val_loss: 0.6457 - val_accuracy: 0.8403\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6103 - accuracy: 0.8448 - val_loss: 0.5446 - val_accuracy: 0.8623\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5286 - accuracy: 0.8629 - val_loss: 0.4796 - val_accuracy: 0.8776\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4738 - accuracy: 0.8753 - val_loss: 0.4338 - val_accuracy: 0.8852\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4344 - accuracy: 0.8846 - val_loss: 0.4018 - val_accuracy: 0.8916\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4050 - accuracy: 0.8910 - val_loss: 0.3769 - val_accuracy: 0.8978\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3821 - accuracy: 0.8967 - val_loss: 0.3577 - val_accuracy: 0.9010\n",
      "Running experiment with initialization: he_normal, activation: tanh\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.5799 - accuracy: 0.8475 - val_loss: 0.3396 - val_accuracy: 0.9083\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3142 - accuracy: 0.9120 - val_loss: 0.2714 - val_accuracy: 0.9256\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2643 - accuracy: 0.9245 - val_loss: 0.2361 - val_accuracy: 0.9322\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2329 - accuracy: 0.9338 - val_loss: 0.2131 - val_accuracy: 0.9400\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2098 - accuracy: 0.9396 - val_loss: 0.1961 - val_accuracy: 0.9437\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1915 - accuracy: 0.9453 - val_loss: 0.1807 - val_accuracy: 0.9488\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1766 - accuracy: 0.9501 - val_loss: 0.1699 - val_accuracy: 0.9516\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1642 - accuracy: 0.9531 - val_loss: 0.1602 - val_accuracy: 0.9537\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1535 - accuracy: 0.9566 - val_loss: 0.1540 - val_accuracy: 0.9561\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1439 - accuracy: 0.9590 - val_loss: 0.1471 - val_accuracy: 0.9580\n",
      "Running experiment with initialization: he_normal, activation: relu\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5711 - accuracy: 0.8453 - val_loss: 0.3093 - val_accuracy: 0.9127\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2861 - accuracy: 0.9178 - val_loss: 0.2528 - val_accuracy: 0.9278\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2370 - accuracy: 0.9318 - val_loss: 0.2130 - val_accuracy: 0.9358\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2048 - accuracy: 0.9412 - val_loss: 0.1906 - val_accuracy: 0.9415\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1811 - accuracy: 0.9477 - val_loss: 0.1760 - val_accuracy: 0.9454\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1630 - accuracy: 0.9532 - val_loss: 0.1533 - val_accuracy: 0.9530\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1478 - accuracy: 0.9576 - val_loss: 0.1396 - val_accuracy: 0.9581\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1355 - accuracy: 0.9618 - val_loss: 0.1337 - val_accuracy: 0.9607\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1252 - accuracy: 0.9643 - val_loss: 0.1265 - val_accuracy: 0.9636\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1164 - accuracy: 0.9665 - val_loss: 0.1232 - val_accuracy: 0.9630\n",
      "Running experiment with initialization: he_normal, activation: leaky_relu\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5778 - accuracy: 0.8400 - val_loss: 0.3184 - val_accuracy: 0.9073\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2923 - accuracy: 0.9166 - val_loss: 0.2554 - val_accuracy: 0.9254\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2461 - accuracy: 0.9295 - val_loss: 0.2205 - val_accuracy: 0.9367\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2161 - accuracy: 0.9389 - val_loss: 0.1987 - val_accuracy: 0.9437\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1947 - accuracy: 0.9439 - val_loss: 0.1817 - val_accuracy: 0.9484\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1774 - accuracy: 0.9498 - val_loss: 0.1696 - val_accuracy: 0.9519\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1630 - accuracy: 0.9536 - val_loss: 0.1600 - val_accuracy: 0.9541\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1516 - accuracy: 0.9568 - val_loss: 0.1495 - val_accuracy: 0.9569\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1414 - accuracy: 0.9599 - val_loss: 0.1462 - val_accuracy: 0.9582\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1328 - accuracy: 0.9622 - val_loss: 0.1376 - val_accuracy: 0.9600\n",
      "Initialization: zeros, Activation: sigmoid\n",
      "Final Accuracy: 0.1094, Final Validation Accuracy: 0.1135, Error Rate: 0.8906\n",
      "Convergence Time: 83.29 seconds\n",
      "-------------------\n",
      "Initialization: zeros, Activation: tanh\n",
      "Final Accuracy: 0.1124, Final Validation Accuracy: 0.1135, Error Rate: 0.8876\n",
      "Convergence Time: 82.67 seconds\n",
      "-------------------\n",
      "Initialization: zeros, Activation: relu\n",
      "Final Accuracy: 0.1124, Final Validation Accuracy: 0.1135, Error Rate: 0.8876\n",
      "Convergence Time: 54.91 seconds\n",
      "-------------------\n",
      "Initialization: zeros, Activation: leaky_relu\n",
      "Final Accuracy: 0.1124, Final Validation Accuracy: 0.1135, Error Rate: 0.8876\n",
      "Convergence Time: 55.98 seconds\n",
      "-------------------\n",
      "Initialization: random_normal, Activation: sigmoid\n",
      "Final Accuracy: 0.7731, Final Validation Accuracy: 0.7963, Error Rate: 0.2269\n",
      "Convergence Time: 55.01 seconds\n",
      "-------------------\n",
      "Initialization: random_normal, Activation: tanh\n",
      "Final Accuracy: 0.9514, Final Validation Accuracy: 0.9521, Error Rate: 0.0486\n",
      "Convergence Time: 82.87 seconds\n",
      "-------------------\n",
      "Initialization: random_normal, Activation: relu\n",
      "Final Accuracy: 0.9488, Final Validation Accuracy: 0.9500, Error Rate: 0.0512\n",
      "Convergence Time: 83.06 seconds\n",
      "-------------------\n",
      "Initialization: random_normal, Activation: leaky_relu\n",
      "Final Accuracy: 0.9450, Final Validation Accuracy: 0.9455, Error Rate: 0.0550\n",
      "Convergence Time: 57.94 seconds\n",
      "-------------------\n",
      "Initialization: glorot_uniform, Activation: sigmoid\n",
      "Final Accuracy: 0.8911, Final Validation Accuracy: 0.8976, Error Rate: 0.1089\n",
      "Convergence Time: 57.96 seconds\n",
      "-------------------\n",
      "Initialization: glorot_uniform, Activation: tanh\n",
      "Final Accuracy: 0.9571, Final Validation Accuracy: 0.9568, Error Rate: 0.0429\n",
      "Convergence Time: 83.01 seconds\n",
      "-------------------\n",
      "Initialization: glorot_uniform, Activation: relu\n",
      "Final Accuracy: 0.9630, Final Validation Accuracy: 0.9602, Error Rate: 0.0370\n",
      "Convergence Time: 58.48 seconds\n",
      "-------------------\n",
      "Initialization: glorot_uniform, Activation: leaky_relu\n",
      "Final Accuracy: 0.9584, Final Validation Accuracy: 0.9579, Error Rate: 0.0416\n",
      "Convergence Time: 57.29 seconds\n",
      "-------------------\n",
      "Initialization: he_normal, Activation: sigmoid\n",
      "Final Accuracy: 0.8967, Final Validation Accuracy: 0.9010, Error Rate: 0.1033\n",
      "Convergence Time: 56.58 seconds\n",
      "-------------------\n",
      "Initialization: he_normal, Activation: tanh\n",
      "Final Accuracy: 0.9590, Final Validation Accuracy: 0.9580, Error Rate: 0.0410\n",
      "Convergence Time: 55.64 seconds\n",
      "-------------------\n",
      "Initialization: he_normal, Activation: relu\n",
      "Final Accuracy: 0.9665, Final Validation Accuracy: 0.9630, Error Rate: 0.0335\n",
      "Convergence Time: 82.66 seconds\n",
      "-------------------\n",
      "Initialization: he_normal, Activation: leaky_relu\n",
      "Final Accuracy: 0.9622, Final Validation Accuracy: 0.9600, Error Rate: 0.0378\n",
      "Convergence Time: 61.76 seconds\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_data, train_labels), (test_data, test_labels) = mnist.load_data()\n",
    "train_data, test_data = train_data / 255.0, test_data / 255.0  # Normalize pixel values\n",
    "\n",
    "# Part 1: Initialization methods\n",
    "def build_model(init_method, activation_func):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "    model.add(layers.Dense(64, kernel_initializer=init_method, activation=activation_func))\n",
    "    model.add(layers.Dense(64, kernel_initializer=init_method, activation=activation_func))\n",
    "    model.add(layers.Dense(10, kernel_initializer=init_method, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Part 2: Activation functions\n",
    "activation_functions = {\n",
    "    'sigmoid': tf.nn.sigmoid,\n",
    "    'tanh': tf.nn.tanh,\n",
    "    'relu': tf.nn.relu,\n",
    "    'leaky_relu': tf.nn.leaky_relu\n",
    "}\n",
    "\n",
    "# Part 3: Perform experiments\n",
    "def run_experiment(init_method, activation_func, epochs=10):\n",
    "    model = build_model(init_method, activation_func)\n",
    "    model.compile(optimizer=optimizers.SGD(learning_rate=0.01),\n",
    "                  loss=losses.sparse_categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    history = model.fit(train_data, train_labels, epochs=epochs, batch_size=32, validation_data=(test_data, test_labels))\n",
    "    end_time = time.time()\n",
    "\n",
    "    return history, end_time - start_time\n",
    "\n",
    "# Experiment configurations\n",
    "initialization_methods = ['zeros', 'random_normal', 'glorot_uniform', 'he_normal']\n",
    "activation_functions = {\n",
    "    'sigmoid': tf.nn.sigmoid,\n",
    "    'tanh': tf.nn.tanh,\n",
    "    'relu': tf.nn.relu,\n",
    "    'leaky_relu': tf.nn.leaky_relu\n",
    "}\n",
    "num_epochs = 10\n",
    "\n",
    "results = {}\n",
    "for init_method in initialization_methods:\n",
    "    for activation_func_name, activation_func in activation_functions.items():\n",
    "        print(f\"Running experiment with initialization: {init_method}, activation: {activation_func_name}\")\n",
    "        history, convergence_time = run_experiment(init_method, activation_func, epochs=num_epochs)\n",
    "        results[(init_method, activation_func_name)] = {\n",
    "            'history': history,\n",
    "            'convergence_time': convergence_time\n",
    "        }\n",
    "\n",
    "# Analyze results (error rate and accuracy)\n",
    "for key, value in results.items():\n",
    "    init_method, activation_func_name = key\n",
    "    history = value['history']\n",
    "    accuracy = history.history['accuracy'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    error_rate = 1.0 - accuracy\n",
    "    print(f\"Initialization: {init_method}, Activation: {activation_func_name}\")\n",
    "    print(f\"Final Accuracy: {accuracy:.4f}, Final Validation Accuracy: {val_accuracy:.4f}, Error Rate: {error_rate:.4f}\")\n",
    "    print(f\"Convergence Time: {value['convergence_time']:.2f} seconds\")\n",
    "    print(\"-------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
